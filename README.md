# Yi-Zhen, Zhang's Machine Learning Portfolio
I'm a graduate of National Tsing Hua University (NTHU), one of the best university in Taiwan. My journey into the world of machine learning began about four years ago. My prior experiences are primarily related to natural language processing, especially focusing on document summarization as my master thesis topic. I am currently actively seeking opportunities in the roles of machine learning engineer, data scientist, or data analyst. 

## Projects

- [**College Application Summarization**](https://github.com/pclightyear/College_Application_Summarization): provide summarization for college applications to aid the review process of the committee. This repository is the implementation of my master thesis "[**Provide Multi-Perspective Summarization for College Applications**](https://ndltd.ncl.edu.tw/cgi-bin/gs32/gsweb.cgi/login?o=dnclcdr&s=id=%22111NTHU5394015%22.&searchmode=basic)".

- [Predicting News Popularity](https://github.com/pclightyear/Predicting_News_Popularity): predict the popularity of the news articles, competition from the deep learning course of NTHU

- [Abstract Labeling Competition](https://github.com/pclightyear/AI_Cup_Abstract_Labeling_Competition): predict the type of sentences in abstract, competition from the [AI Cup](https://tbrain.trendmicro.com.tw/Competitions/Details/8).

- [Emotion Recognition on Twitter](https://github.com/pclightyear/Twitter_Emotion_Recognition): predict the emotion behind the tweets, competition from the data mining course of NTHU.

- [Machine Learning 100 Days Challenge](https://github.com/pclightyear/2nd-ML100Days): my start to learn the fundamental machine learning theory.


## Tools

Below is the list of the major tools or libraries I used in my past project.

- Pytorch: the deep learning framework I used during the journey of my master thesis. I'm also experienced with Tensorflow as I started to learn deep learning.

- HuggingFace: the open-source machine learning playground I used during the journey of my master thesis.

- NLTK: the mainstream natural language processing toolkit.

- Scikit-learn: the core library in preprocessing and building baselines in the early stage of each machine learning project.

- [Articut](https://api.droidtown.co/): a linguistic rule-based tool for Traditional Chinese word segmentation and part of speech tagging.

- [Data Version Control](https://dvc.org/): the version control tool of the datasets (lots of pdf ~100 GB) of my master thesis.

## Contact
ee91608@gmail.com

[My LinkedIn](https://www.linkedin.com/in/yi-zhen-zhang/)
